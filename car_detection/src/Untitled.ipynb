{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import test_hog_subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= Initializing Training Dataset ================================\n",
      "Total Vehicle Images Loaded: 1416\n",
      "Total Non-Vehicle Images Loaded: 1489\n",
      "Shape of features list is  (2905, 1536)\n",
      "Shape of label list is  (2905,)\n",
      "Accuracy is   0.9655765920826161\n",
      "============================= Training Video ================================\n",
      "[1280, 720]\n",
      "No of Windows are  1664\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import moviepy\n",
    "from skimage.feature import hog\n",
    "from moviepy.editor import VideoFileClip\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.ndimage.measurements import label\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "# 2.1 Experimenting with Color Spaces\n",
    "# Extract Color Space\n",
    "\n",
    "def extract_color_histogram(image, nbins=32, bins_range=(0, 255), resize=None):\n",
    "    if resize is not None:\n",
    "        image = cv2.resize(image, resize)\n",
    "    zero_channel = np.histogram(image[:, :, 0], bins=nbins, range=bins_range)\n",
    "    first_channel = np.histogram(image[:, :, 1], bins=nbins, range=bins_range)\n",
    "    second_channel = np.histogram(image[:, :, 2], bins=nbins, range=bins_range)\n",
    "    return zero_channel, first_channel, second_channel\n",
    "\n",
    "\n",
    "def find_bin_center(histogram_channel):\n",
    "    bin_edges = histogram_channel[1]\n",
    "    bin_centers = (bin_edges[1:] + bin_edges[0:len(bin_edges) - 1]) / 2\n",
    "    return bin_centers\n",
    "\n",
    "\n",
    "def extract_color_features(zero_channel, first_channel, second_channel):\n",
    "    return np.concatenate((zero_channel[0], first_channel[0], second_channel[0]))\n",
    "\n",
    "\n",
    "def spatial_binning_features(image, size):\n",
    "    image = cv2.resize(image, size)\n",
    "    return image.ravel()\n",
    "\n",
    "\n",
    "# featureList=SpatialBinningFeatures(vehicle_images_original[1],(16,16))\n",
    "# print(featureList.shape)\n",
    "\n",
    "def get_features_from_hog(image, orient, cells_per_block, pixels_per_cell, visualize=False, feature_vector_flag=True):\n",
    "    if visualize:\n",
    "        hog_features, hog_image = hog(image,\n",
    "                                      orientations=orient,\n",
    "                                      pixels_per_cell=(pixels_per_cell, pixels_per_cell),\n",
    "                                      cells_per_block=(cells_per_block, cells_per_block),\n",
    "                                      visualize=True,\n",
    "                                      feature_vector=feature_vector_flag)\n",
    "        return hog_features, hog_image\n",
    "    else:\n",
    "        hog_features = hog(image,\n",
    "                           orientations=orient,\n",
    "                           pixels_per_cell=(pixels_per_cell, pixels_per_cell),\n",
    "                           cells_per_block=(cells_per_block, cells_per_block),\n",
    "                           visualize=False,\n",
    "                           feature_vector=feature_vector_flag)\n",
    "        return hog_features\n",
    "\n",
    "\n",
    "def convert_image_colorspace(image, colorspace):\n",
    "    return cv2.cvtColor(image, colorspace)\n",
    "\n",
    "\n",
    "def extract_features(images, orientation, cells_per_block, pixels_per_cell, convert_colorspace=False):\n",
    "    feature_list = []\n",
    "    for image in images:\n",
    "        if convert_colorspace:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        local_features_1 = get_features_from_hog(image[:, :, 0], orientation, cells_per_block, pixels_per_cell, False,\n",
    "                                                 True)\n",
    "        local_features_2 = get_features_from_hog(image[:, :, 1], orientation, cells_per_block, pixels_per_cell, False,\n",
    "                                                 True)\n",
    "        local_features_3 = get_features_from_hog(image[:, :, 2], orientation, cells_per_block, pixels_per_cell, False,\n",
    "                                                 True)\n",
    "        x = np.hstack([local_features_1, local_features_2, local_features_3])\n",
    "        feature_list.append(x)\n",
    "    return feature_list\n",
    "\n",
    "\n",
    "def draw_boxes(img, bounding_boxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "\n",
    "    for bounding_box in bounding_boxes:\n",
    "        r = random.randint(0, 255)\n",
    "        g = random.randint(0, 255)\n",
    "        b = random.randint(0, 255)\n",
    "        color = (r, g, b)\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bounding_box[0], bounding_box[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "\n",
    "def sliding_window(img, x_start_stop=[None, None], y_start_stop=[None, None],\n",
    "                   xy_window=(64, 64), xy_overlap=(0.9, 0.9)):\n",
    "    if x_start_stop[0] is None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] is None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] is None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] is None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "\n",
    "    window_list = []\n",
    "\n",
    "    image_width_x = x_start_stop[1] - x_start_stop[0]\n",
    "    image_width_y = y_start_stop[1] - y_start_stop[0]\n",
    "\n",
    "    windows_x = np.int(1 + (image_width_x - xy_window[0]) / (xy_window[0] * xy_overlap[0]))\n",
    "    windows_y = np.int(1 + (image_width_y - xy_window[1]) / (xy_window[1] * xy_overlap[1]))\n",
    "\n",
    "    modified_window_size = xy_window\n",
    "    for i in range(0, windows_y):\n",
    "        # modified_window_size = np.add(modified_window_size , 3)\n",
    "\n",
    "        y_start = y_start_stop[0] + np.int(i * modified_window_size[1] * xy_overlap[1])\n",
    "        for j in range(0, windows_x):\n",
    "            x_start = x_start_stop[0] + np.int(j * modified_window_size[0] * xy_overlap[0])\n",
    "\n",
    "            x1 = np.int(x_start + modified_window_size[0])\n",
    "            y1 = np.int(y_start + modified_window_size[1])\n",
    "            window_list.append(((x_start, y_start), (x1, y1)))\n",
    "    return window_list\n",
    "\n",
    "\n",
    "def draw_cars(image, windows, linear_svc, orientation, cells_per_block, pixels_per_cell, convert_colorspace=False):\n",
    "    refined_windows = []\n",
    "    for window in windows:\n",
    "        start = window[0]\n",
    "        end = window[1]\n",
    "        clipped_image = image[start[1]:end[1], start[0]:end[0]]\n",
    "\n",
    "        if clipped_image.shape[1] == clipped_image.shape[0] and clipped_image.shape[1] != 0:\n",
    "            clipped_image = cv2.resize(clipped_image, (64, 64))\n",
    "            f1 = extract_features([clipped_image], orientation, cells_per_block, pixels_per_cell, convert_colorspace)\n",
    "            predicted_output = linear_svc.predict([f1[0]])\n",
    "            if predicted_output == 1:\n",
    "                refined_windows.append(window)\n",
    "    return refined_windows\n",
    "\n",
    "\n",
    "def add_heat(heatmap, bounding_boxes):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bounding_boxes:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap  # Iterate through list of bboxes\n",
    "\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "\n",
    "def draw_labeled_bounding_boxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1] + 1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0, 0, 255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "\n",
    "def pipeline(image, windows, linear_svc, orientation, cells_per_block, pixels_per_cell, convert_colorspace):\n",
    "    refined_windows = draw_cars(image, windows, linear_svc, orientation, cells_per_block, pixels_per_cell,\n",
    "                                convert_colorspace)\n",
    "    heat = np.zeros_like(image[:, :, 0]).astype(np.float)\n",
    "    heat = add_heat(heat, refined_windows)\n",
    "    heat = apply_threshold(heat, 1)\n",
    "    heat_map = np.clip(heat, 0, 255)\n",
    "    labels = label(heat_map)\n",
    "    draw_img = draw_labeled_bounding_boxes(np.copy(image), labels)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(draw_img)\n",
    "    plt.title('Car Positions')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(heat_map, cmap='hot')\n",
    "    plt.title('Heat Map')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return draw_img\n",
    "\n",
    "\n",
    "def videoPipeline(pathToInputVideoClip, pathToOutputVideoClip, linear_svc, orientation, cells_per_block,\n",
    "                  pixels_per_cell, convert_colorspace):\n",
    "\n",
    "    print(\"============================= Training Video ================================\")\n",
    "    video_input = VideoFileClip(pathToInputVideoClip)\n",
    "\n",
    "    print(video_input.size)  # [1280, 720]\n",
    "\n",
    "    image = mpimg.imread('test_image.jpg')\n",
    "\n",
    "    x_start_stop = [0, video_input.size[0]]\n",
    "    y_start_stop = [int(video_input.size[1] / 2), 660]\n",
    "\n",
    "    # xy_window_half = (32, 32)\n",
    "    # xy_overlap_half = (0.20, 0.20)\n",
    "    # windows_half = slide_window(image, x_start_stop, [400, 480],\n",
    "    #                             xy_window_half, xy_overlap_half)\n",
    "    xy_window = (64, 64)\n",
    "    xy_overlap = (0.15, 0.15)\n",
    "    windows_normal = sliding_window(image, x_start_stop, [int(video_input.size[1] / 2), 528],\n",
    "                                    xy_window, xy_overlap)\n",
    "    xy_window_1_5 = (96, 96)\n",
    "    xy_window_1_5_overlap = (0.30, 0.30)\n",
    "    windows_1_5 = sliding_window(image, x_start_stop, [int(video_input.size[1] / 2), 588],\n",
    "                                 xy_window_1_5, xy_window_1_5_overlap)\n",
    "    xy_window_twice_overlap = (0.50, 0.50)\n",
    "    xy_window_twice = (128, 128)\n",
    "    windows_twice = sliding_window(image, x_start_stop, y_start_stop,\n",
    "                                   xy_window_twice, xy_window_twice_overlap)\n",
    "\n",
    "    windows = windows_normal + windows_1_5 + windows_twice\n",
    "    print(\"No of Windows are \", len(windows))\n",
    "\n",
    "    out_img  = pipeline(image, windows,linear_svc, orientation, cells_per_block, pixels_per_cell, convert_colorspace)\n",
    "    plt.imshow(out_img)\n",
    "    #processed_video = video_input.fl_image(lambda image: pipeline(image,\n",
    "    #                                                              windows,\n",
    "    #                                                              linear_svc,\n",
    "    #                                                              orientation,\n",
    "    #                                                              cells_per_block,\n",
    "    #                                                              pixels_per_cell,\n",
    "    #                                                              convert_colorspace))\n",
    "    #processed_video.write_videofile(pathToOutputVideoClip, threads=8, audio=False, fps=24)\n",
    "    #video_input.reader.close()\n",
    "    #video_input.audio.reader.close_proc()\n",
    "\n",
    "\n",
    "def initialization(vehicle_arr, nonvehicle_arr):\n",
    "    print(\"============================= Initializing Training Dataset ================================\")\n",
    "\n",
    "    # Reading vehicle images from its path stored in the vehicle_arr\n",
    "    vehicle_rgb = []\n",
    "    for image_path in vehicle_arr:\n",
    "        read_image = cv2.imread(image_path)\n",
    "        rgb_image = cv2.cvtColor(read_image, cv2.COLOR_BGR2RGB)\n",
    "        vehicle_rgb.append(rgb_image)\n",
    "\n",
    "    print(\"Total Vehicle Images Loaded: \" + str(len(vehicle_arr)))\n",
    "\n",
    "    # Reading non-vehicle images from its path stored in the nonvehicle_arr\n",
    "    nonvehicle_rgb = []\n",
    "    for image_path in nonvehicle_arr:\n",
    "        read_image = cv2.imread(image_path)\n",
    "        rgb_image = cv2.cvtColor(read_image, cv2.COLOR_BGR2RGB)\n",
    "        nonvehicle_rgb.append(rgb_image)\n",
    "\n",
    "    print(\"Total Non-Vehicle Images Loaded: \" + str(len(nonvehicle_rgb)))\n",
    "    return vehicle_rgb, nonvehicle_rgb\n",
    "\n",
    "\n",
    "def main():\n",
    "    #Path to all vehicle data set\n",
    "    vehicle_far = glob.glob('../vehicles/GTI_Far//*.png')\n",
    "    vehicle_left = glob.glob('../vehicles/GTI_Left//*.png')\n",
    "    vehicle_middle = glob.glob('../vehicles/MiddleClose//*.png')\n",
    "    vehicle_right = glob.glob('../vehicles/GTI_Right//*.png')\n",
    "    vehicle_KITTI = glob.glob('../vehicles/KITTI_extracted//*.png')\n",
    "    vehicle_arr = np.concatenate([vehicle_far, vehicle_left, vehicle_middle, vehicle_right, vehicle_KITTI])\n",
    "    # Path to all non-vehicle data set\n",
    "    nonvehicle_Extras = glob.glob('../non-vehicles/Extras/*.png')\n",
    "    nonvehicle_GTI = glob.glob('../non-vehicles/GTI/*.png')\n",
    "    nonvehicle_arr = np.concatenate([nonvehicle_Extras, nonvehicle_GTI])\n",
    "\n",
    "    vehicle_rgb, nonvehicle_rgb = initialization(vehicle_arr, nonvehicle_arr)\n",
    "\n",
    "    # good results with: 9 2 16\n",
    "    orientation = 8\n",
    "    cells_per_block = 1\n",
    "    pixels_per_cell = 8\n",
    "    convert_colorspace = True  # YUV\n",
    "\n",
    "    vehicle_features = extract_features(vehicle_rgb, orientation, cells_per_block, pixels_per_cell, convert_colorspace)\n",
    "    nonvehicle_features = extract_features(nonvehicle_rgb, orientation, cells_per_block, pixels_per_cell,\n",
    "                                           convert_colorspace)\n",
    "\n",
    "    feature_list = np.vstack([vehicle_features, nonvehicle_features])\n",
    "    label_list = np.concatenate([np.ones(len(vehicle_features)), np.zeros(len(nonvehicle_features))])\n",
    "\n",
    "    print(\"Shape of features list is \", feature_list.shape)\n",
    "    print(\"Shape of label list is \", label_list.shape)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(feature_list, label_list, test_size=0.2, shuffle=True)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    X_train_scaled = scaler.transform(x_train)\n",
    "    X_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "    linear_svc = LinearSVC()\n",
    "    linear_svc.fit(x_train, y_train)\n",
    "    print(\"Accuracy is  \", linear_svc.score(x_test, y_test))\n",
    "\n",
    "    pathToInputVideoClip = 'project_video_Trim3.mp4'\n",
    "    pathToOutputVideoClip = 'testVideo.mp4'\n",
    "    videoPipeline(pathToInputVideoClip, pathToOutputVideoClip, linear_svc, orientation, cells_per_block,\n",
    "                  pixels_per_cell, convert_colorspace)\n",
    "    exit()\n",
    "\n",
    "\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3] *",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
